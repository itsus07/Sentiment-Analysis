{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212957c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Activation,Conv1D,MaxPooling1D,Dropout,LSTM, Bidirectional, GlobalMaxPooling1D,LeakyReLU\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d96dd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646f8610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec5b9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e8174c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40523f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt') # Used for sentence tokenizer\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d8d44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_preprocess(review):\n",
    "    \"\"\"\n",
    "    Takes in a string of review, then performs the following:\n",
    "    1. Remove HTML tag from review\n",
    "    2. Remove URLs from review\n",
    "    3. Make entire review lowercase\n",
    "    4. Split the review in words\n",
    "    5. Remove all punctuation\n",
    "    6. Remove empty strings from review\n",
    "    7. Remove all stopwords\n",
    "    8. Returns a list of the cleaned review after jioning them back to a sentence\n",
    "    \"\"\"\n",
    "    en_stops = set(stopwords.words('english'))\n",
    "    \n",
    "    \"\"\"\n",
    "    Removing HTML tag from review\n",
    "    \"\"\"\n",
    "    clean = re.compile('<.*?>')\n",
    "    review_without_tag = re.sub(clean, '', review) \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Removing URLs\n",
    "    \"\"\"\n",
    "    review_without_tag_and_url = re.sub(r\"http\\S+\", \"\", review_without_tag)\n",
    "    \n",
    "    review_without_tag_and_url = re.sub(r\"www\\S+\", \"\", review_without_tag)\n",
    "    \n",
    "    \"\"\"\n",
    "    Make entire string lowercase\n",
    "    \"\"\"\n",
    "    review_lowercase = review_without_tag_and_url.lower()\n",
    "    \n",
    "    \"\"\"\n",
    "    Split string into words\n",
    "    \"\"\"\n",
    "    list_of_words = word_tokenize(review_lowercase)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Remove punctuation\n",
    "    Checking characters to see if they are in punctuation\n",
    "    \"\"\"\n",
    "\n",
    "    list_of_words_without_punctuation=[''.join(this_char for this_char in this_string if (this_char in string.ascii_lowercase))for this_string in list_of_words]\n",
    "     \n",
    "    \n",
    "    \"\"\"\n",
    "    Remove empty strings\n",
    "    \"\"\"\n",
    "    list_of_words_without_punctuation = list(filter(None, list_of_words_without_punctuation))\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Remove any stopwords\n",
    "    \"\"\"\n",
    "  \n",
    "    filtered_word_list = [w for w in list_of_words_without_punctuation if w not in en_stops] \n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a list of the cleaned review after jioning them back to a sentence\n",
    "    \"\"\"\n",
    "    return ' '.join(filtered_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b5d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(review_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4ac563c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one reviewers mentioned watching oz episode ho...\n",
       "1    wonderful little production filming technique ...\n",
       "2    thought wonderful way spend time hot summer we...\n",
       "3    basically family little boy jake thinks zombie...\n",
       "4    petter mattei love time money visually stunnin...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09a4153a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([1 if sentiment == 'positive' else 0 for sentiment in df['sentiment']])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0006c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8660541d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34707,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27efb688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14875,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e5dd844",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([1 if sentiment == 'positive' else 0 for sentiment in y_train])\n",
    "y_test = np.array([1 if sentiment == 'positive' else 0 for sentiment in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57dc3795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14875,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84e6c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c30767ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(df['review'], vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b593396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d6b0f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgWord2vec(doc):\n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd17fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49582/49582 [01:18<00:00, 630.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "x = []\n",
    "for i in tqdm(range(len(df['review']))):\n",
    "    #print(\"Applying avg word2vec\",i)\n",
    "    x.append(avgWord2vec(df['review'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e584c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = np.array(x)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "794f16cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(df['sentiment'])\n",
    "y = y.iloc[:,1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "213b7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xnew,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85556d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model_analysis = GaussianNB().fit(X_train,y_train)\n",
    "prediction = model_analysis.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6869eadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5823333669456489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.61      0.59      4909\n",
      "        True       0.59      0.56      0.57      5008\n",
      "\n",
      "    accuracy                           0.58      9917\n",
      "   macro avg       0.58      0.58      0.58      9917\n",
      "weighted avg       0.58      0.58      0.58      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report as cr\n",
    "\n",
    "score=accuracy_score(y_test,prediction)\n",
    "print(score)\n",
    "print(cr(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "868aa960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5937279419179188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.59      0.59      4909\n",
      "        True       0.60      0.60      0.60      5008\n",
      "\n",
      "    accuracy                           0.59      9917\n",
      "   macro avg       0.59      0.59      0.59      9917\n",
      "weighted avg       0.59      0.59      0.59      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model_analysis5 = AdaBoostClassifier().fit(X_train,y_train)\n",
    "Prediction5 = model_analysis5.predict(X_test)\n",
    "score=accuracy_score(y_test,Prediction5)\n",
    "print(score)\n",
    "print(cr(y_test,Prediction5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70796d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5955430069577493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.60      0.60      4909\n",
      "        True       0.60      0.59      0.60      5008\n",
      "\n",
      "    accuracy                           0.60      9917\n",
      "   macro avg       0.60      0.60      0.60      9917\n",
      "weighted avg       0.60      0.60      0.60      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_analysis2 = RandomForestClassifier().fit(X_train,y_train)\n",
    "Prediction2 = model_analysis2.predict(X_test)\n",
    "score=accuracy_score(y_test,Prediction2)\n",
    "print(score)\n",
    "print(cr(y_test,Prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41ea4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833417364122214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.58      0.58      4909\n",
      "        True       0.59      0.58      0.59      5008\n",
      "\n",
      "    accuracy                           0.58      9917\n",
      "   macro avg       0.58      0.58      0.58      9917\n",
      "weighted avg       0.58      0.58      0.58      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_analysis3 = XGBClassifier().fit(X_train,y_train)\n",
    "Prediction3 = model_analysis3.predict(X_test)\n",
    "score=accuracy_score(y_test,Prediction3)\n",
    "print(score)\n",
    "print(cr(y_test,Prediction3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fc20ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 67,073\n",
      "Trainable params: 67,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(256, activation=LeakyReLU(), input_shape=(100,)))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(128, activation=LeakyReLU()))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(64, activation=LeakyReLU()))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0e84d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3967/3967 [==============================] - 8s 2ms/step - loss: 0.6796 - accuracy: 0.5630 - val_loss: 0.6678 - val_accuracy: 0.5922\n",
      "Epoch 2/10\n",
      "3967/3967 [==============================] - 7s 2ms/step - loss: 0.6708 - accuracy: 0.5888 - val_loss: 0.6701 - val_accuracy: 0.5901\n",
      "Epoch 3/10\n",
      "3967/3967 [==============================] - 7s 2ms/step - loss: 0.6691 - accuracy: 0.5935 - val_loss: 0.6659 - val_accuracy: 0.5991\n",
      "Epoch 4/10\n",
      "3967/3967 [==============================] - 7s 2ms/step - loss: 0.6675 - accuracy: 0.5978 - val_loss: 0.6673 - val_accuracy: 0.5943\n",
      "Epoch 5/10\n",
      "3967/3967 [==============================] - 7s 2ms/step - loss: 0.6664 - accuracy: 0.5986 - val_loss: 0.6883 - val_accuracy: 0.5639\n",
      "Epoch 6/10\n",
      "3967/3967 [==============================] - 7s 2ms/step - loss: 0.6661 - accuracy: 0.6003 - val_loss: 0.6623 - val_accuracy: 0.6025\n",
      "Epoch 7/10\n",
      "3967/3967 [==============================] - 7s 2ms/step - loss: 0.6644 - accuracy: 0.6013 - val_loss: 0.6630 - val_accuracy: 0.6017\n",
      "Epoch 8/10\n",
      "3967/3967 [==============================] - 7s 2ms/step - loss: 0.6645 - accuracy: 0.6017 - val_loss: 0.6617 - val_accuracy: 0.6055\n",
      "Epoch 9/10\n",
      "3967/3967 [==============================] - 7s 2ms/step - loss: 0.6635 - accuracy: 0.6034 - val_loss: 0.6614 - val_accuracy: 0.6006\n",
      "Epoch 10/10\n",
      "3967/3967 [==============================] - 7s 2ms/step - loss: 0.6628 - accuracy: 0.6044 - val_loss: 0.6661 - val_accuracy: 0.5974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f5205efbe0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model6.fit(X_train, y_train, epochs=10, batch_size=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ec1985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction6 = model6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1090b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59735807199758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.45      0.52      4909\n",
      "        True       0.58      0.75      0.65      5008\n",
      "\n",
      "    accuracy                           0.60      9917\n",
      "   macro avg       0.61      0.60      0.59      9917\n",
      "weighted avg       0.61      0.60      0.59      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction6 = []\n",
    "for i in Prediction6:\n",
    "  if i<0.5:\n",
    "    prediction6.append(0)\n",
    "  else:\n",
    "    prediction6.append(1)\n",
    "\n",
    "score=accuracy_score(y_test,prediction6)\n",
    "print(score)\n",
    "print(cr(y_test,prediction6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640692ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
